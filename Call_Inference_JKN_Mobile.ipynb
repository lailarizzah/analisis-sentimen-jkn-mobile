{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cell Inference Analisis Sentimen JKN Mobile\n",
        "\n",
        "Cell ini digunakan untuk memprediksi sentimen dari suatu kalimat input. Model yang digunakan adalah Bi-LSTM yang telah dilatih sebelumnya menggunakan dataset sentimen.  \n",
        "\n",
        "Cara penggunaan:\n",
        "1. Masukkan kalimat yang ingin diprediksi pada input yang disediakan.\n",
        "2. Model akan memproses kalimat dan menampilkan prediksi sentimen (positif, negatif, atau netral).\n",
        "\n",
        "Catatan:\n",
        "* Akurasi model bergantung pada kualitas dan kuantitas data latih yang digunakan.\n",
        "* Model telah dioptimalkan untuk mendeteksi sentimen dalam konteks tertentu dan mungkin kurang akurat pada konteks yang berbeda.\n",
        "* Anda dapat meningkatkan akurasi model dengan menambahkan data latih yang lebih beragam dan relevan.\n",
        "\n",
        "Contoh penggunaan:"
      ],
      "metadata": {
        "id": "tya0eExz_F3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIHMnVXCLp7e",
        "outputId": "4e664dc9-eef0-419a-b2e1-c4a3aed1ac3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the model, tokenizer, and label encoder\n",
        "!wget -q https://raw.githubusercontent.com/lailarizzah/analisis-sentimen-jkn-mobile/main/data%20cell%20inference/bilstm_model.keras -O bilstm_model.keras\n",
        "!wget -q https://raw.githubusercontent.com/lailarizzah/analisis-sentimen-jkn-mobile/main/data%20cell%20inference/tokenizer.pkl -O tokenizer.pkl\n",
        "!wget -q https://raw.githubusercontent.com/lailarizzah/analisis-sentimen-jkn-mobile/main/data%20cell%20inference/label_encoder.pkl -O label_encoder.pkl\n",
        "\n",
        "model = tf.keras.models.load_model(\"bilstm_model.keras\")\n",
        "\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "# --- Add custom words here, including strong negative words --- #\n",
        "new_words = ['lemot', 'loading lama', 'sering macet', 'bagus', 'mantap', 'mudah', 'sulit', 'ribet', 'buruk',\n",
        "            'bajingan', 'sampah', 'goblok', 'tolol', 'anjing', 'bangsat']  # tambahkan kata-kata kasar lainnya\n",
        "for word in new_words:\n",
        "    if word not in tokenizer.word_index:\n",
        "        tokenizer.word_index[word] = len(tokenizer.word_index) + 1\n",
        "# --- End of custom words --- #\n",
        "\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "# Fungsi untuk membersihkan teks\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
        "    # Modifikasi regex untuk mempertahankan tanda seru dan tanda tanya\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s!?]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# Fungsi untuk memproses kalimat sebelum prediksi\n",
        "def preprocess_sentence(sentence, tokenizer, max_len):\n",
        "    cleaned = clean_text(sentence)\n",
        "    seq = tokenizer.texts_to_sequences([cleaned])\n",
        "    padded = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    return padded\n",
        "\n",
        "# Dapatkan panjang maksimum input untuk model\n",
        "# Instead of using model.input_shape, get maxlen from the training parameters or the tokenizer\n",
        "# Assuming you used maxlen = 100 during training:\n",
        "max_length = 100\n",
        "\n",
        "# Input kalimat dari pengguna\n",
        "kalimat_baru = input(\"Masukkan kalimat baru: \")\n",
        "\n",
        "# Proses kalimat dan lakukan prediksi\n",
        "X_baru = preprocess_sentence(kalimat_baru, tokenizer, max_length)\n",
        "pred_prob = model.predict(X_baru)\n",
        "pred_label = np.argmax(pred_prob)\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "print(\"Sentimen kalimat tersebut adalah:\", label_encoder.inverse_transform([pred_label])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YVxl0rW7YpG",
        "outputId": "8e55d9ac-8a16-4e2b-e0af-081b39b08fb9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukkan kalimat baru: aplikasi jkn biasa aja sih\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
            "Sentimen kalimat tersebut adalah: neutral\n"
          ]
        }
      ]
    }
  ]
}